save_data: data/
src_vocab: data/en.vocab
tgt_vocab: data/es.vocab
overwrite: False

# Corpora:
data:
    corpus_1:
        path_src: ../Corpus/train.en
        path_tgt: ../Corpus/train.es
    valid:
        path_src: ../Corpus/dev.en
        path_tgt: ../Corpus/dev.es
# Model
decoder_type: rnn
encoder_type: rnn
word_vec_size: 512
rnn_size: 512
hidden_size: 64
rnn_type: GRU
layers: 3
# transformer_ff: 256
# heads: 4
# accum_count: 8
# warmup_steps: 8000
optim: adam
adam_beta1: 0.9
adam_beta2: 0.998
decay_method: noam
learning_rate: 2.0
max_grad_norm: 0.0
batch_size: 128
batch_type: tokens
normalization: tokens
dropout: 0.4
label_smoothing: 0.1
max_generator_batches: 2
param_init: 0.0
param_init_glorot: 'true'
position_encoding: 'true'

# Train on a single GPU
world_size: 1
gpu_ranks:
  - 0

# Checkpoints
save_model: models/modelo
save_checkpoint_steps: 1000
train_steps: 33000
valid_steps: 500
keep_checkpoint: 10
report_every: 100
skip_empty_level: silent
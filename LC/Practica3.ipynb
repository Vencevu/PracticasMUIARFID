{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desarrollar y evaluar un Chunker utilizando el corpus ConLL2000 del NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     C:\\Users\\Alberto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP Confidence/NN)\n",
      "  (PP in/IN)\n",
      "  (NP the/DT pound/NN)\n",
      "  (VP is/VBZ widely/RB expected/VBN to/TO take/VB)\n",
      "  (NP another/DT sharp/JJ dive/NN)\n",
      "  if/IN\n",
      "  (NP trade/NN figures/NNS)\n",
      "  (PP for/IN)\n",
      "  (NP September/NNP)\n",
      "  ,/,\n",
      "  due/JJ\n",
      "  (PP for/IN)\n",
      "  (NP release/NN)\n",
      "  (NP tomorrow/NN)\n",
      "  ,/,\n",
      "  (VP fail/VB to/TO show/VB)\n",
      "  (NP a/DT substantial/JJ improvement/NN)\n",
      "  (PP from/IN)\n",
      "  (NP July/NNP and/CC August/NNP)\n",
      "  (NP 's/POS near-record/JJ deficits/NNS)\n",
      "  ./.)\n",
      "-------\n",
      "(S\n",
      "  (NP Rockwell/NNP International/NNP Corp./NNP)\n",
      "  (NP 's/POS Tulsa/NNP unit/NN)\n",
      "  (VP said/VBD)\n",
      "  (NP it/PRP)\n",
      "  (VP signed/VBD)\n",
      "  (NP a/DT tentative/JJ agreement/NN)\n",
      "  (VP extending/VBG)\n",
      "  (NP its/PRP$ contract/NN)\n",
      "  (PP with/IN)\n",
      "  (NP Boeing/NNP Co./NNP)\n",
      "  (VP to/TO provide/VB)\n",
      "  (NP structural/JJ parts/NNS)\n",
      "  (PP for/IN)\n",
      "  (NP Boeing/NNP)\n",
      "  (NP 's/POS 747/CD jetliners/NNS)\n",
      "  ./.)\n",
      "[('Rockwell', 'NNP', 'B-NP'), ('International', 'NNP', 'I-NP'), ('Corp.', 'NNP', 'I-NP'), (\"'s\", 'POS', 'B-NP'), ('Tulsa', 'NNP', 'I-NP'), ('unit', 'NN', 'I-NP'), ('said', 'VBD', 'B-VP'), ('it', 'PRP', 'B-NP'), ('signed', 'VBD', 'B-VP'), ('a', 'DT', 'B-NP'), ('tentative', 'JJ', 'I-NP'), ('agreement', 'NN', 'I-NP'), ('extending', 'VBG', 'B-VP'), ('its', 'PRP$', 'B-NP'), ('contract', 'NN', 'I-NP'), ('with', 'IN', 'B-PP'), ('Boeing', 'NNP', 'B-NP'), ('Co.', 'NNP', 'I-NP'), ('to', 'TO', 'B-VP'), ('provide', 'VB', 'I-VP'), ('structural', 'JJ', 'B-NP'), ('parts', 'NNS', 'I-NP'), ('for', 'IN', 'B-PP'), ('Boeing', 'NNP', 'B-NP'), (\"'s\", 'POS', 'B-NP'), ('747', 'CD', 'I-NP'), ('jetliners', 'NNS', 'I-NP'), ('.', '.', 'O')]\n",
      "----\n",
      "[('NN', 'B-NP'), ('IN', 'B-PP'), ('DT', 'B-NP'), ('NN', 'I-NP'), ('VBZ', 'B-VP'), ('RB', 'I-VP'), ('VBN', 'I-VP'), ('TO', 'I-VP'), ('VB', 'I-VP'), ('DT', 'B-NP'), ('JJ', 'I-NP'), ('NN', 'I-NP'), ('IN', 'O'), ('NN', 'B-NP'), ('NNS', 'I-NP'), ('IN', 'B-PP'), ('NNP', 'B-NP'), (',', 'O'), ('JJ', 'O'), ('IN', 'B-PP'), ('NN', 'B-NP'), ('NN', 'B-NP'), (',', 'O'), ('VB', 'B-VP'), ('TO', 'I-VP'), ('VB', 'I-VP'), ('DT', 'B-NP'), ('JJ', 'I-NP'), ('NN', 'I-NP'), ('IN', 'B-PP'), ('NNP', 'B-NP'), ('CC', 'I-NP'), ('NNP', 'I-NP'), ('POS', 'B-NP'), ('JJ', 'I-NP'), ('NNS', 'I-NP'), ('.', 'O')]\n",
      "====\n",
      "[('NNP', 'B-NP'), ('NNP', 'I-NP'), ('NNP', 'I-NP'), ('POS', 'B-NP'), ('NNP', 'I-NP'), ('NN', 'I-NP'), ('VBD', 'B-VP'), ('PRP', 'B-NP'), ('VBD', 'B-VP'), ('DT', 'B-NP'), ('JJ', 'I-NP'), ('NN', 'I-NP'), ('VBG', 'B-VP'), ('PRP$', 'B-NP'), ('NN', 'I-NP'), ('IN', 'B-PP'), ('NNP', 'B-NP'), ('NNP', 'I-NP'), ('TO', 'B-VP'), ('VB', 'I-VP'), ('JJ', 'B-NP'), ('NNS', 'I-NP'), ('IN', 'B-PP'), ('NNP', 'B-NP'), ('POS', 'B-NP'), ('CD', 'I-NP'), ('NNS', 'I-NP'), ('.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "# Importar y trabajar con el corpus conll2000\n",
    "\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"conll2000\")\n",
    "from nltk.corpus import conll2000\n",
    "conll_train = conll2000.chunked_sents('train.txt')\n",
    "conll_test = conll2000.chunked_sents('test.txt')\n",
    "print (conll_train[0])\n",
    "print (\"-------\")\n",
    "print (conll_test[0])\n",
    "\n",
    "import nltk.chunk\n",
    "train_chunks = [nltk.chunk.tree2conlltags(tree) for tree in conll_train]\n",
    "test_chunks= [nltk.chunk.tree2conlltags(tree) for tree in conll_test]\n",
    "print(test_chunks[0])\n",
    "\n",
    "\n",
    "train=[[(t, c) for (w, t, c) in chunk_tags] for chunk_tags in train_chunks]\n",
    "test= [[(t, c) for (w, t, c) in chunk_tags] for chunk_tags in test_chunks]\n",
    "print(\"----\")\n",
    "print(train[0])\n",
    "print(\"====\")\n",
    "print(test[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 49389 tokens with 21891 phrases; found: 22758 phrases; correct: 19008.\n",
      "accuracy:  92.53%; (non-O)\n",
      "accuracy:  90.55%; precision:  83.52%; recall:  86.83%; FB1:  85.14\n",
      "               NP: precision:  83.76%; recall:  86.45%; FB1:  85.08  12821\n",
      "               PP: precision:  83.50%; recall:  92.16%; FB1:  87.62  5310\n",
      "               VP: precision:  82.88%; recall:  82.33%; FB1:  82.61  4627\n"
     ]
    }
   ],
   "source": [
    "# Entrenar un etiquetador y evaluarlo\n",
    "from nltk.tag import hmm, tnt\n",
    "from conlleval import evaluate_conll_file\n",
    "#Utilizar alguno de los etiquetadores vistos en la práctica 2.\n",
    "tagger = hmm.HiddenMarkovModelTagger.train(train)\n",
    "\n",
    "frases = []\n",
    "# Etiquetar esta frase:\n",
    "for test_chunk in test_chunks:\n",
    "    frase= [(t) for (w, t, c) in test_chunk]\n",
    "    frases.append(frase)\n",
    "\n",
    "tagged_frases = tagger.tag_sents(frases)\n",
    "result = []\n",
    "for i in range(len(tagged_frases)):\n",
    "    frase = test_chunks[i]\n",
    "    for j in range(len(frase)):\n",
    "        palabra = frase[j]\n",
    "        termino = palabra[0]\n",
    "        pos = palabra[1]\n",
    "        chunk_real = palabra[2]\n",
    "        chunk_predict = tagged_frases[i][j][1]\n",
    "        result.append(termino+\" \"+pos+\" \"+chunk_real+\" \"+chunk_predict+\"\\n\")\n",
    "\n",
    "# Esta evaluación no es la que queremos, queremos evaluar a nivel de chunk\n",
    "\n",
    "#Utilizar el evaluador: https://github.com/sighsmile/conlleval\n",
    "with open('output.txt') as f:\n",
    "    evaluate_conll_file(f)\n",
    "#Pasos: \n",
    "# 1. Entrenar el modelo\n",
    "# 2. Etiquetar el test\n",
    "# 3. Formatear la salida del test para utilizar 'conlleval' que espera un fichero tipo texto\n",
    "#    con 4 columnas (pal,pos, etiqueta_chunk_gold, etiqueta_predicha). Cada frase se separa \n",
    "#    por blancos.\n",
    "# 4. Evaluar\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('TFG')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "cac8c148fe99531e69ba1d06939db520c9f4997d6650c8223f282d58b7ae5d8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":422,"status":"ok","timestamp":1673515867121,"user":{"displayName":"Vencevú '_'","userId":"04987947938800528309"},"user_tz":-60},"id":"M-icrPLi3Gsq"},"outputs":[],"source":["from __future__ import print_function\n","\n","import keras\n","from keras.datasets import cifar10\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, BatchNormalization as BN, GaussianNoise as GN,  Dense, Activation, Flatten, Dropout as DP\n","from tensorflow.keras.optimizers import SGD, Adamax, Adam, Adagrad\n","from keras.utils import np_utils\n","\n","from keras.callbacks import LearningRateScheduler as LRS, ReduceLROnPlateau as RLROP\n","from keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1673515867122,"user":{"displayName":"Vencevú '_'","userId":"04987947938800528309"},"user_tz":-60},"id":"BP7O-h1x3s1D"},"outputs":[],"source":["batch_size = 64\n","num_classes = 10\n","epochs = 2000\n","dropout = 0.2"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1323,"status":"ok","timestamp":1673515868442,"user":{"displayName":"Vencevú '_'","userId":"04987947938800528309"},"user_tz":-60},"id":"VmaFWFAn3yVy","outputId":"e063b764-701e-48ed-cbb4-d3cefa969abc"},"outputs":[{"name":"stdout","output_type":"stream","text":["(50000, 32, 32, 3)\n","(10000, 32, 32, 3)\n"]}],"source":["#### LOAD AND TRANSFORM\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","\n","x_train /= 255\n","x_test /= 255\n","\n","print(x_train.shape)\n","print(x_test.shape)\n","\n","y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1673515868444,"user":{"displayName":"Vencevú '_'","userId":"04987947938800528309"},"user_tz":-60},"id":"jtWspKGq3zdB"},"outputs":[],"source":["## DEFINE A DATA AUGMENTATION GENERATOR\n","\n","datagen = ImageDataGenerator(\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    rotation_range=20,\n","    zoom_range=[1.0,1.2],\n","    shear_range = 10,\n","    horizontal_flip=True)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lIZha9hs35ty","outputId":"8fc328a5-477f-452c-b342-618225a80d1c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 32, 32, 32)        896       \n","                                                                 \n"," batch_normalization (BatchN  (None, 32, 32, 32)       128       \n"," ormalization)                                                   \n","                                                                 \n"," gaussian_noise (GaussianNoi  (None, 32, 32, 32)       0         \n"," se)                                                             \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 32, 32, 32)       128       \n"," hNormalization)                                                 \n","                                                                 \n"," gaussian_noise_1 (GaussianN  (None, 32, 32, 32)       0         \n"," oise)                                                           \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 32, 32, 32)        9248      \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 32, 32, 32)       128       \n"," hNormalization)                                                 \n","                                                                 \n"," gaussian_noise_2 (GaussianN  (None, 32, 32, 32)       0         \n"," oise)                                                           \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 32, 32, 32)        9248      \n","                                                                 \n"," batch_normalization_3 (Batc  (None, 32, 32, 32)       128       \n"," hNormalization)                                                 \n","                                                                 \n"," gaussian_noise_3 (GaussianN  (None, 32, 32, 32)       0         \n"," oise)                                                           \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n"," )                                                               \n","                                                                 \n"," dropout (Dropout)           (None, 16, 16, 32)        0         \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 16, 16, 64)        18496     \n","                                                                 \n"," batch_normalization_4 (Batc  (None, 16, 16, 64)       256       \n"," hNormalization)                                                 \n","                                                                 \n"," gaussian_noise_4 (GaussianN  (None, 16, 16, 64)       0         \n"," oise)                                                           \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 16, 16, 64)        36928     \n","                                                                 \n"," batch_normalization_5 (Batc  (None, 16, 16, 64)       256       \n"," hNormalization)                                                 \n","                                                                 \n"," gaussian_noise_5 (GaussianN  (None, 16, 16, 64)       0         \n"," oise)                                                           \n","                                                                 \n"," conv2d_6 (Conv2D)           (None, 16, 16, 64)        36928     \n","                                                                 \n"," batch_normalization_6 (Batc  (None, 16, 16, 64)       256       \n"," hNormalization)                                                 \n","                                                                 \n"," gaussian_noise_6 (GaussianN  (None, 16, 16, 64)       0         \n"," oise)                                                           \n","                                                                 \n"," conv2d_7 (Conv2D)           (None, 16, 16, 64)        36928     \n","                                                                 \n"," batch_normalization_7 (Batc  (None, 16, 16, 64)       256       \n"," hNormalization)                                                 \n","                                                                 \n"," gaussian_noise_7 (GaussianN  (None, 16, 16, 64)       0         \n"," oise)                                                           \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n","                                                                 \n"," conv2d_8 (Conv2D)           (None, 8, 8, 128)         73856     \n","                                                                 \n"," batch_normalization_8 (Batc  (None, 8, 8, 128)        512       \n"," hNormalization)                                                 \n","                                                                 \n"," gaussian_noise_8 (GaussianN  (None, 8, 8, 128)        0         \n"," oise)                                                           \n","                                                                 \n"," conv2d_9 (Conv2D)           (None, 8, 8, 128)         147584    \n","                                                                 \n"," batch_normalization_9 (Batc  (None, 8, 8, 128)        512       \n"," hNormalization)                                                 \n","                                                                 \n"," gaussian_noise_9 (GaussianN  (None, 8, 8, 128)        0         \n"," oise)                                                           \n","                                                                 \n"," conv2d_10 (Conv2D)          (None, 8, 8, 128)         147584    \n","                                                                 \n"," batch_normalization_10 (Bat  (None, 8, 8, 128)        512       \n"," chNormalization)                                                \n","                                                                 \n"," gaussian_noise_10 (Gaussian  (None, 8, 8, 128)        0         \n"," Noise)                                                          \n","                                                                 \n"," conv2d_11 (Conv2D)          (None, 8, 8, 128)         147584    \n","                                                                 \n"," batch_normalization_11 (Bat  (None, 8, 8, 128)        512       \n"," chNormalization)                                                \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 4, 4, 128)        0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_2 (Dropout)         (None, 4, 4, 128)         0         \n","                                                                 \n"," conv2d_12 (Conv2D)          (None, 4, 4, 256)         295168    \n","                                                                 \n"," batch_normalization_12 (Bat  (None, 4, 4, 256)        1024      \n"," chNormalization)                                                \n","                                                                 \n"," gaussian_noise_11 (Gaussian  (None, 4, 4, 256)        0         \n"," Noise)                                                          \n","                                                                 \n"," conv2d_13 (Conv2D)          (None, 4, 4, 256)         590080    \n","                                                                 \n"," batch_normalization_13 (Bat  (None, 4, 4, 256)        1024      \n"," chNormalization)                                                \n","                                                                 \n"," gaussian_noise_12 (Gaussian  (None, 4, 4, 256)        0         \n"," Noise)                                                          \n","                                                                 \n"," conv2d_14 (Conv2D)          (None, 4, 4, 256)         590080    \n","                                                                 \n"," batch_normalization_14 (Bat  (None, 4, 4, 256)        1024      \n"," chNormalization)                                                \n","                                                                 \n"," gaussian_noise_13 (Gaussian  (None, 4, 4, 256)        0         \n"," Noise)                                                          \n","                                                                 \n"," conv2d_15 (Conv2D)          (None, 4, 4, 256)         590080    \n","                                                                 \n"," batch_normalization_15 (Bat  (None, 4, 4, 256)        1024      \n"," chNormalization)                                                \n","                                                                 \n"," gaussian_noise_14 (Gaussian  (None, 4, 4, 256)        0         \n"," Noise)                                                          \n","                                                                 \n"," max_pooling2d_3 (MaxPooling  (None, 2, 2, 256)        0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_3 (Dropout)         (None, 2, 2, 256)         0         \n","                                                                 \n"," conv2d_16 (Conv2D)          (None, 2, 2, 512)         1180160   \n","                                                                 \n"," batch_normalization_16 (Bat  (None, 2, 2, 512)        2048      \n"," chNormalization)                                                \n","                                                                 \n"," gaussian_noise_15 (Gaussian  (None, 2, 2, 512)        0         \n"," Noise)                                                          \n","                                                                 \n"," conv2d_17 (Conv2D)          (None, 2, 2, 512)         2359808   \n","                                                                 \n"," batch_normalization_17 (Bat  (None, 2, 2, 512)        2048      \n"," chNormalization)                                                \n","                                                                 \n"," gaussian_noise_16 (Gaussian  (None, 2, 2, 512)        0         \n"," Noise)                                                          \n","                                                                 \n"," conv2d_18 (Conv2D)          (None, 2, 2, 512)         2359808   \n","                                                                 \n"," batch_normalization_18 (Bat  (None, 2, 2, 512)        2048      \n"," chNormalization)                                                \n","                                                                 \n"," gaussian_noise_17 (Gaussian  (None, 2, 2, 512)        0         \n"," Noise)                                                          \n","                                                                 \n"," conv2d_19 (Conv2D)          (None, 2, 2, 512)         2359808   \n","                                                                 \n"," batch_normalization_19 (Bat  (None, 2, 2, 512)        2048      \n"," chNormalization)                                                \n","                                                                 \n"," gaussian_noise_18 (Gaussian  (None, 2, 2, 512)        0         \n"," Noise)                                                          \n","                                                                 \n"," max_pooling2d_4 (MaxPooling  (None, 1, 1, 512)        0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_4 (Dropout)         (None, 1, 1, 512)         0         \n","                                                                 \n"," flatten (Flatten)           (None, 512)               0         \n","                                                                 \n"," dense (Dense)               (None, 256)               131328    \n","                                                                 \n"," batch_normalization_20 (Bat  (None, 256)              1024      \n"," chNormalization)                                                \n","                                                                 \n"," dropout_5 (Dropout)         (None, 256)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 10)                2570      \n","                                                                 \n","=================================================================\n","Total params: 11,150,314\n","Trainable params: 11,141,866\n","Non-trainable params: 8,448\n","_________________________________________________________________\n","Epoch 1/2000\n","781/781 [==============================] - 59s 65ms/step - loss: 2.2480 - accuracy: 0.1981 - val_loss: 2.0332 - val_accuracy: 0.2745 - lr: 0.0010\n","Epoch 2/2000\n","781/781 [==============================] - 49s 63ms/step - loss: 1.8653 - accuracy: 0.3003 - val_loss: 2.4168 - val_accuracy: 0.2973 - lr: 0.0010\n","Epoch 3/2000\n","781/781 [==============================] - 48s 62ms/step - loss: 1.6576 - accuracy: 0.3787 - val_loss: 1.6949 - val_accuracy: 0.4388 - lr: 0.0010\n","Epoch 4/2000\n","781/781 [==============================] - 49s 63ms/step - loss: 1.5091 - accuracy: 0.4453 - val_loss: 2.3151 - val_accuracy: 0.4486 - lr: 0.0010\n","Epoch 5/2000\n","781/781 [==============================] - 49s 63ms/step - loss: 1.3922 - accuracy: 0.5074 - val_loss: 1.4724 - val_accuracy: 0.5705 - lr: 0.0010\n","Epoch 6/2000\n","781/781 [==============================] - 49s 63ms/step - loss: 1.2741 - accuracy: 0.5550 - val_loss: 1.2016 - val_accuracy: 0.6109 - lr: 0.0010\n","Epoch 7/2000\n","781/781 [==============================] - 49s 63ms/step - loss: 1.1885 - accuracy: 0.5902 - val_loss: 1.3006 - val_accuracy: 0.6076 - lr: 0.0010\n","Epoch 8/2000\n","781/781 [==============================] - 49s 63ms/step - loss: 1.1189 - accuracy: 0.6171 - val_loss: 1.0274 - val_accuracy: 0.6793 - lr: 0.0010\n","Epoch 9/2000\n","781/781 [==============================] - 49s 62ms/step - loss: 1.0678 - accuracy: 0.6368 - val_loss: 1.0782 - val_accuracy: 0.6790 - lr: 0.0010\n","Epoch 10/2000\n","781/781 [==============================] - 49s 63ms/step - loss: 1.0153 - accuracy: 0.6586 - val_loss: 0.8922 - val_accuracy: 0.7197 - lr: 0.0010\n","Epoch 11/2000\n","781/781 [==============================] - 49s 63ms/step - loss: 0.9717 - accuracy: 0.6785 - val_loss: 0.9862 - val_accuracy: 0.7006 - lr: 0.0010\n","Epoch 12/2000\n","781/781 [==============================] - 49s 63ms/step - loss: 0.9233 - accuracy: 0.6914 - val_loss: 1.0538 - val_accuracy: 0.6912 - lr: 0.0010\n","Epoch 13/2000\n","781/781 [==============================] - 49s 62ms/step - loss: 0.8899 - accuracy: 0.7070 - val_loss: 0.7588 - val_accuracy: 0.7553 - lr: 0.0010\n","Epoch 14/2000\n","781/781 [==============================] - 49s 63ms/step - loss: 0.8614 - accuracy: 0.7174 - val_loss: 0.8019 - val_accuracy: 0.7582 - lr: 0.0010\n","Epoch 15/2000\n","781/781 [==============================] - 49s 63ms/step - loss: 0.8301 - accuracy: 0.7286 - val_loss: 0.9694 - val_accuracy: 0.7213 - lr: 0.0010\n","Epoch 16/2000\n","781/781 [==============================] - 49s 63ms/step - loss: 0.8049 - accuracy: 0.7381 - val_loss: 0.7979 - val_accuracy: 0.7614 - lr: 0.0010\n","Epoch 17/2000\n","781/781 [==============================] - 49s 62ms/step - loss: 0.7773 - accuracy: 0.7481 - val_loss: 0.8137 - val_accuracy: 0.7642 - lr: 0.0010\n","Epoch 18/2000\n","781/781 [==============================] - 49s 63ms/step - loss: 0.7547 - accuracy: 0.7543 - val_loss: 0.7429 - val_accuracy: 0.7674 - lr: 0.0010\n","Epoch 19/2000\n","781/781 [==============================] - 48s 62ms/step - loss: 0.7390 - accuracy: 0.7610 - val_loss: 0.6570 - val_accuracy: 0.7896 - lr: 0.0010\n","Epoch 20/2000\n","781/781 [==============================] - 48s 62ms/step - loss: 0.7205 - accuracy: 0.7688 - val_loss: 0.6816 - val_accuracy: 0.7910 - lr: 0.0010\n","Epoch 21/2000\n","781/781 [==============================] - 48s 62ms/step - loss: 0.7131 - accuracy: 0.7710 - val_loss: 0.7514 - val_accuracy: 0.7754 - lr: 0.0010\n","Epoch 22/2000\n","781/781 [==============================] - 43s 55ms/step - loss: 0.6841 - accuracy: 0.7797 - val_loss: 0.5814 - val_accuracy: 0.8175 - lr: 0.0010\n","Epoch 23/2000\n","781/781 [==============================] - 26s 33ms/step - loss: 0.6772 - accuracy: 0.7804 - val_loss: 0.6959 - val_accuracy: 0.7922 - lr: 0.0010\n","Epoch 24/2000\n","781/781 [==============================] - 26s 33ms/step - loss: 0.6555 - accuracy: 0.7889 - val_loss: 0.5639 - val_accuracy: 0.8251 - lr: 0.0010\n","Epoch 25/2000\n","781/781 [==============================] - 26s 33ms/step - loss: 0.6470 - accuracy: 0.7912 - val_loss: 0.5387 - val_accuracy: 0.8321 - lr: 0.0010\n","Epoch 26/2000\n","781/781 [==============================] - 26s 33ms/step - loss: 0.6384 - accuracy: 0.7927 - val_loss: 0.5613 - val_accuracy: 0.8272 - lr: 0.0010\n","Epoch 27/2000\n","781/781 [==============================] - 26s 33ms/step - loss: 0.6148 - accuracy: 0.8018 - val_loss: 0.5401 - val_accuracy: 0.8308 - lr: 0.0010\n","Epoch 28/2000\n","781/781 [==============================] - 26s 33ms/step - loss: 0.6099 - accuracy: 0.8046 - val_loss: 0.4894 - val_accuracy: 0.8478 - lr: 0.0010\n","Epoch 29/2000\n","781/781 [==============================] - 26s 33ms/step - loss: 0.5915 - accuracy: 0.8086 - val_loss: 0.5089 - val_accuracy: 0.8419 - lr: 0.0010\n","Epoch 30/2000\n","781/781 [==============================] - 45s 57ms/step - loss: 0.5931 - accuracy: 0.8119 - val_loss: 0.4847 - val_accuracy: 0.8455 - lr: 0.0010\n","Epoch 31/2000\n","781/781 [==============================] - 37s 47ms/step - loss: 0.5832 - accuracy: 0.8127 - val_loss: 0.5340 - val_accuracy: 0.8324 - lr: 0.0010\n","Epoch 32/2000\n","781/781 [==============================] - 29s 38ms/step - loss: 0.5666 - accuracy: 0.8175 - val_loss: 0.4784 - val_accuracy: 0.8465 - lr: 0.0010\n","Epoch 33/2000\n","781/781 [==============================] - 27s 34ms/step - loss: 0.5578 - accuracy: 0.8207 - val_loss: 0.4630 - val_accuracy: 0.8538 - lr: 0.0010\n","Epoch 34/2000\n","781/781 [==============================] - 46s 59ms/step - loss: 0.5431 - accuracy: 0.8247 - val_loss: 0.4753 - val_accuracy: 0.8523 - lr: 0.0010\n","Epoch 35/2000\n","781/781 [==============================] - 48s 62ms/step - loss: 0.5424 - accuracy: 0.8251 - val_loss: 0.4439 - val_accuracy: 0.8588 - lr: 0.0010\n","Epoch 36/2000\n","781/781 [==============================] - 45s 58ms/step - loss: 0.5317 - accuracy: 0.8288 - val_loss: 0.5433 - val_accuracy: 0.8349 - lr: 0.0010\n","Epoch 37/2000\n","781/781 [==============================] - 29s 38ms/step - loss: 0.5249 - accuracy: 0.8318 - val_loss: 0.4313 - val_accuracy: 0.8633 - lr: 0.0010\n","Epoch 38/2000\n","781/781 [==============================] - 29s 37ms/step - loss: 0.5167 - accuracy: 0.8332 - val_loss: 0.5523 - val_accuracy: 0.8345 - lr: 0.0010\n","Epoch 39/2000\n","781/781 [==============================] - 29s 37ms/step - loss: 0.5105 - accuracy: 0.8362 - val_loss: 0.4315 - val_accuracy: 0.8625 - lr: 0.0010\n","Epoch 40/2000\n","781/781 [==============================] - 29s 37ms/step - loss: 0.5051 - accuracy: 0.8348 - val_loss: 0.4874 - val_accuracy: 0.8508 - lr: 0.0010\n","Epoch 41/2000\n","781/781 [==============================] - 29s 38ms/step - loss: 0.4954 - accuracy: 0.8405 - val_loss: 0.3968 - val_accuracy: 0.8744 - lr: 0.0010\n","Epoch 42/2000\n","781/781 [==============================] - 29s 37ms/step - loss: 0.4943 - accuracy: 0.8418 - val_loss: 0.4102 - val_accuracy: 0.8680 - lr: 0.0010\n","Epoch 43/2000\n","781/781 [==============================] - 29s 37ms/step - loss: 0.4828 - accuracy: 0.8452 - val_loss: 0.4641 - val_accuracy: 0.8508 - lr: 0.0010\n","Epoch 44/2000\n","781/781 [==============================] - 29s 37ms/step - loss: 0.4812 - accuracy: 0.8456 - val_loss: 0.4398 - val_accuracy: 0.8576 - lr: 0.0010\n","Epoch 45/2000\n","781/781 [==============================] - 28s 35ms/step - loss: 0.4781 - accuracy: 0.8475 - val_loss: 0.4059 - val_accuracy: 0.8731 - lr: 0.0010\n","Epoch 46/2000\n","781/781 [==============================] - 33s 42ms/step - loss: 0.4691 - accuracy: 0.8475 - val_loss: 0.3873 - val_accuracy: 0.8714 - lr: 0.0010\n","Epoch 47/2000\n","781/781 [==============================] - 40s 51ms/step - loss: 0.4716 - accuracy: 0.8476 - val_loss: 0.4440 - val_accuracy: 0.8633 - lr: 0.0010\n","Epoch 48/2000\n","781/781 [==============================] - 29s 37ms/step - loss: 0.4596 - accuracy: 0.8517 - val_loss: 0.4015 - val_accuracy: 0.8713 - lr: 0.0010\n","Epoch 49/2000\n","781/781 [==============================] - 29s 38ms/step - loss: 0.4553 - accuracy: 0.8525 - val_loss: 0.3678 - val_accuracy: 0.8839 - lr: 0.0010\n","Epoch 50/2000\n","781/781 [==============================] - 29s 37ms/step - loss: 0.4456 - accuracy: 0.8557 - val_loss: 0.3900 - val_accuracy: 0.8782 - lr: 0.0010\n","Epoch 51/2000\n","781/781 [==============================] - 29s 37ms/step - loss: 0.4490 - accuracy: 0.8547 - val_loss: 0.4477 - val_accuracy: 0.8596 - lr: 0.0010\n","Epoch 52/2000\n","781/781 [==============================] - 34s 44ms/step - loss: 0.4444 - accuracy: 0.8557 - val_loss: 0.3667 - val_accuracy: 0.8808 - lr: 0.0010\n","Epoch 53/2000\n","781/781 [==============================] - 29s 37ms/step - loss: 0.4416 - accuracy: 0.8575 - val_loss: 0.3746 - val_accuracy: 0.8787 - lr: 0.0010\n","Epoch 54/2000\n","781/781 [==============================] - 29s 37ms/step - loss: 0.4369 - accuracy: 0.8583 - val_loss: 0.4251 - val_accuracy: 0.8697 - lr: 0.0010\n","Epoch 55/2000\n","781/781 [==============================] - 26s 33ms/step - loss: 0.4287 - accuracy: 0.8620 - val_loss: 0.3747 - val_accuracy: 0.8811 - lr: 0.0010\n","Epoch 56/2000\n","781/781 [==============================] - 28s 36ms/step - loss: 0.4272 - accuracy: 0.8619 - val_loss: 0.3737 - val_accuracy: 0.8816 - lr: 0.0010\n","Epoch 57/2000\n","781/781 [==============================] - 49s 63ms/step - loss: 0.4210 - accuracy: 0.8630 - val_loss: 0.3582 - val_accuracy: 0.8881 - lr: 0.0010\n","Epoch 58/2000\n","781/781 [==============================] - 48s 62ms/step - loss: 0.4168 - accuracy: 0.8649 - val_loss: 0.3863 - val_accuracy: 0.8771 - lr: 0.0010\n","Epoch 59/2000\n","781/781 [==============================] - 49s 62ms/step - loss: 0.4117 - accuracy: 0.8672 - val_loss: 0.3832 - val_accuracy: 0.8781 - lr: 0.0010\n","Epoch 60/2000\n","781/781 [==============================] - 49s 62ms/step - loss: 0.4126 - accuracy: 0.8660 - val_loss: 0.3743 - val_accuracy: 0.8828 - lr: 0.0010\n","Epoch 61/2000\n","781/781 [==============================] - 49s 63ms/step - loss: 0.4135 - accuracy: 0.8658 - val_loss: 0.3527 - val_accuracy: 0.8840 - lr: 0.0010\n","Epoch 62/2000\n","781/781 [==============================] - 49s 62ms/step - loss: 0.4078 - accuracy: 0.8686 - val_loss: 0.3527 - val_accuracy: 0.8882 - lr: 0.0010\n","Epoch 63/2000\n","781/781 [==============================] - 49s 63ms/step - loss: 0.3990 - accuracy: 0.8710 - val_loss: 0.3260 - val_accuracy: 0.8949 - lr: 0.0010\n","Epoch 64/2000\n","781/781 [==============================] - 49s 63ms/step - loss: 0.3955 - accuracy: 0.8732 - val_loss: 0.3552 - val_accuracy: 0.8862 - lr: 0.0010\n","Epoch 65/2000\n","781/781 [==============================] - 49s 63ms/step - loss: 0.3919 - accuracy: 0.8754 - val_loss: 0.3660 - val_accuracy: 0.8873 - lr: 0.0010\n","Epoch 66/2000\n","781/781 [==============================] - 49s 62ms/step - loss: 0.3905 - accuracy: 0.8719 - val_loss: 0.3971 - val_accuracy: 0.8793 - lr: 0.0010\n","Epoch 67/2000\n","781/781 [==============================] - 49s 63ms/step - loss: 0.3898 - accuracy: 0.8734 - val_loss: 0.3508 - val_accuracy: 0.8886 - lr: 0.0010\n","Epoch 68/2000\n","781/781 [==============================] - 49s 63ms/step - loss: 0.3800 - accuracy: 0.8764 - val_loss: 0.3515 - val_accuracy: 0.8899 - lr: 0.0010\n","Epoch 69/2000\n","781/781 [==============================] - 49s 62ms/step - loss: 0.3803 - accuracy: 0.8770 - val_loss: 0.3404 - val_accuracy: 0.8936 - lr: 0.0010\n","Epoch 70/2000\n","781/781 [==============================] - 49s 63ms/step - loss: 0.3792 - accuracy: 0.8754 - val_loss: 0.3421 - val_accuracy: 0.8896 - lr: 0.0010\n","Epoch 71/2000\n","781/781 [==============================] - 49s 62ms/step - loss: 0.3791 - accuracy: 0.8760 - val_loss: 0.3504 - val_accuracy: 0.8862 - lr: 0.0010\n","Epoch 72/2000\n","781/781 [==============================] - 49s 63ms/step - loss: 0.3734 - accuracy: 0.8804 - val_loss: 0.3092 - val_accuracy: 0.9024 - lr: 0.0010\n","Epoch 73/2000\n","781/781 [==============================] - 49s 63ms/step - loss: 0.3684 - accuracy: 0.8805 - val_loss: 0.3660 - val_accuracy: 0.8849 - lr: 0.0010\n","Epoch 74/2000\n","781/781 [==============================] - 45s 57ms/step - loss: 0.3646 - accuracy: 0.8815 - val_loss: 0.3630 - val_accuracy: 0.8871 - lr: 0.0010\n","Epoch 75/2000\n","781/781 [==============================] - 44s 56ms/step - loss: 0.3638 - accuracy: 0.8829 - val_loss: 0.3340 - val_accuracy: 0.8984 - lr: 0.0010\n","Epoch 76/2000\n","781/781 [==============================] - 44s 56ms/step - loss: 0.3612 - accuracy: 0.8839 - val_loss: 0.3509 - val_accuracy: 0.8896 - lr: 0.0010\n","Epoch 77/2000\n","781/781 [==============================] - 44s 56ms/step - loss: 0.3605 - accuracy: 0.8829 - val_loss: 0.3308 - val_accuracy: 0.8960 - lr: 0.0010\n","Epoch 78/2000\n","781/781 [==============================] - 44s 56ms/step - loss: 0.3591 - accuracy: 0.8838 - val_loss: 0.3328 - val_accuracy: 0.8917 - lr: 0.0010\n","Epoch 79/2000\n","781/781 [==============================] - 44s 56ms/step - loss: 0.3542 - accuracy: 0.8846 - val_loss: 0.3117 - val_accuracy: 0.9016 - lr: 0.0010\n","Epoch 80/2000\n","781/781 [==============================] - 44s 56ms/step - loss: 0.3516 - accuracy: 0.8864 - val_loss: 0.3192 - val_accuracy: 0.8989 - lr: 0.0010\n","Epoch 81/2000\n","781/781 [==============================] - 44s 56ms/step - loss: 0.3485 - accuracy: 0.8882 - val_loss: 0.3105 - val_accuracy: 0.9027 - lr: 0.0010\n","Epoch 82/2000\n","781/781 [==============================] - 44s 56ms/step - loss: 0.3446 - accuracy: 0.8875 - val_loss: 0.3123 - val_accuracy: 0.9001 - lr: 0.0010\n","Epoch 83/2000\n","781/781 [==============================] - 44s 56ms/step - loss: 0.3153 - accuracy: 0.8973 - val_loss: 0.2892 - val_accuracy: 0.9071 - lr: 5.0000e-04\n","Epoch 84/2000\n","781/781 [==============================] - 44s 56ms/step - loss: 0.2997 - accuracy: 0.9021 - val_loss: 0.3101 - val_accuracy: 0.9011 - lr: 5.0000e-04\n","Epoch 85/2000\n","781/781 [==============================] - 44s 56ms/step - loss: 0.2980 - accuracy: 0.9020 - val_loss: 0.2923 - val_accuracy: 0.9079 - lr: 5.0000e-04\n","Epoch 86/2000\n","781/781 [==============================] - 44s 56ms/step - loss: 0.2939 - accuracy: 0.9030 - val_loss: 0.2999 - val_accuracy: 0.9066 - lr: 5.0000e-04\n","Epoch 87/2000\n","781/781 [==============================] - 44s 56ms/step - loss: 0.2915 - accuracy: 0.9057 - val_loss: 0.2830 - val_accuracy: 0.9111 - lr: 5.0000e-04\n","Epoch 88/2000\n","781/781 [==============================] - 44s 56ms/step - loss: 0.2956 - accuracy: 0.9038 - val_loss: 0.2856 - val_accuracy: 0.9099 - lr: 5.0000e-04\n","Epoch 89/2000\n","781/781 [==============================] - 45s 57ms/step - loss: 0.2926 - accuracy: 0.9038 - val_loss: 0.2736 - val_accuracy: 0.9139 - lr: 5.0000e-04\n","Epoch 90/2000\n","781/781 [==============================] - 49s 63ms/step - loss: 0.2890 - accuracy: 0.9063 - val_loss: 0.2913 - val_accuracy: 0.9070 - lr: 5.0000e-04\n","Epoch 91/2000\n","781/781 [==============================] - 32s 41ms/step - loss: 0.2875 - accuracy: 0.9067 - val_loss: 0.2842 - val_accuracy: 0.9110 - lr: 5.0000e-04\n","Epoch 92/2000\n","781/781 [==============================] - 30s 38ms/step - loss: 0.2855 - accuracy: 0.9056 - val_loss: 0.3154 - val_accuracy: 0.9039 - lr: 5.0000e-04\n","Epoch 93/2000\n","781/781 [==============================] - 29s 37ms/step - loss: 0.2806 - accuracy: 0.9069 - val_loss: 0.2810 - val_accuracy: 0.9135 - lr: 5.0000e-04\n","Epoch 94/2000\n","781/781 [==============================] - 29s 37ms/step - loss: 0.2767 - accuracy: 0.9088 - val_loss: 0.2979 - val_accuracy: 0.9054 - lr: 5.0000e-04\n","Epoch 95/2000\n","781/781 [==============================] - 29s 37ms/step - loss: 0.2797 - accuracy: 0.9079 - val_loss: 0.2769 - val_accuracy: 0.9128 - lr: 5.0000e-04\n","Epoch 96/2000\n","781/781 [==============================] - 29s 37ms/step - loss: 0.2766 - accuracy: 0.9090 - val_loss: 0.2714 - val_accuracy: 0.9145 - lr: 5.0000e-04\n","Epoch 97/2000\n","781/781 [==============================] - 29s 37ms/step - loss: 0.2746 - accuracy: 0.9100 - val_loss: 0.2870 - val_accuracy: 0.9099 - lr: 5.0000e-04\n","Epoch 98/2000\n","781/781 [==============================] - 28s 36ms/step - loss: 0.2715 - accuracy: 0.9108 - val_loss: 0.2979 - val_accuracy: 0.9079 - lr: 5.0000e-04\n","Epoch 99/2000\n","781/781 [==============================] - 26s 33ms/step - loss: 0.2677 - accuracy: 0.9115 - val_loss: 0.2812 - val_accuracy: 0.9148 - lr: 5.0000e-04\n","Epoch 100/2000\n","781/781 [==============================] - 26s 33ms/step - loss: 0.2670 - accuracy: 0.9122 - val_loss: 0.2874 - val_accuracy: 0.9099 - lr: 5.0000e-04\n","Epoch 101/2000\n","781/781 [==============================] - 26s 33ms/step - loss: 0.2650 - accuracy: 0.9137 - val_loss: 0.3018 - val_accuracy: 0.9059 - lr: 5.0000e-04\n","Epoch 102/2000\n","781/781 [==============================] - 26s 34ms/step - loss: 0.2653 - accuracy: 0.9119 - val_loss: 0.2887 - val_accuracy: 0.9108 - lr: 5.0000e-04\n","Epoch 103/2000\n","781/781 [==============================] - 26s 33ms/step - loss: 0.2669 - accuracy: 0.9115 - val_loss: 0.2914 - val_accuracy: 0.9114 - lr: 5.0000e-04\n","Epoch 104/2000\n","781/781 [==============================] - 26s 33ms/step - loss: 0.2606 - accuracy: 0.9133 - val_loss: 0.2752 - val_accuracy: 0.9112 - lr: 5.0000e-04\n","Epoch 105/2000\n","781/781 [==============================] - 26s 33ms/step - loss: 0.2636 - accuracy: 0.9139 - val_loss: 0.2707 - val_accuracy: 0.9150 - lr: 5.0000e-04\n","Epoch 106/2000\n","781/781 [==============================] - 26s 33ms/step - loss: 0.2603 - accuracy: 0.9141 - val_loss: 0.2927 - val_accuracy: 0.9134 - lr: 5.0000e-04\n","Epoch 107/2000\n","781/781 [==============================] - 26s 33ms/step - loss: 0.2564 - accuracy: 0.9142 - val_loss: 0.2741 - val_accuracy: 0.9168 - lr: 5.0000e-04\n","Epoch 108/2000\n","781/781 [==============================] - 26s 33ms/step - loss: 0.2601 - accuracy: 0.9157 - val_loss: 0.2757 - val_accuracy: 0.9132 - lr: 5.0000e-04\n","Epoch 109/2000\n","781/781 [==============================] - 27s 35ms/step - loss: 0.2572 - accuracy: 0.9137 - val_loss: 0.2751 - val_accuracy: 0.9153 - lr: 5.0000e-04\n","Epoch 110/2000\n","781/781 [==============================] - 37s 48ms/step - loss: 0.2580 - accuracy: 0.9148 - val_loss: 0.2640 - val_accuracy: 0.9166 - lr: 5.0000e-04\n","Epoch 111/2000\n","781/781 [==============================] - 43s 55ms/step - loss: 0.2547 - accuracy: 0.9157 - val_loss: 0.2746 - val_accuracy: 0.9152 - lr: 5.0000e-04\n","Epoch 112/2000\n","781/781 [==============================] - 28s 36ms/step - loss: 0.2555 - accuracy: 0.9165 - val_loss: 0.2897 - val_accuracy: 0.9123 - lr: 5.0000e-04\n","Epoch 113/2000\n","781/781 [==============================] - 33s 43ms/step - loss: 0.2519 - accuracy: 0.9158 - val_loss: 0.2890 - val_accuracy: 0.9128 - lr: 5.0000e-04\n","Epoch 114/2000\n","781/781 [==============================] - 30s 38ms/step - loss: 0.2475 - accuracy: 0.9185 - val_loss: 0.2832 - val_accuracy: 0.9133 - lr: 5.0000e-04\n","Epoch 115/2000\n","781/781 [==============================] - 30s 38ms/step - loss: 0.2520 - accuracy: 0.9173 - val_loss: 0.2721 - val_accuracy: 0.9154 - lr: 5.0000e-04\n","Epoch 116/2000\n","781/781 [==============================] - 30s 38ms/step - loss: 0.2505 - accuracy: 0.9186 - val_loss: 0.2790 - val_accuracy: 0.9129 - lr: 5.0000e-04\n","Epoch 117/2000\n","781/781 [==============================] - 28s 36ms/step - loss: 0.2459 - accuracy: 0.9188 - val_loss: 0.2949 - val_accuracy: 0.9115 - lr: 5.0000e-04\n","Epoch 118/2000\n","781/781 [==============================] - 31s 40ms/step - loss: 0.2530 - accuracy: 0.9176 - val_loss: 0.2863 - val_accuracy: 0.9100 - lr: 5.0000e-04\n","Epoch 119/2000\n","781/781 [==============================] - 31s 40ms/step - loss: 0.2489 - accuracy: 0.9170 - val_loss: 0.2795 - val_accuracy: 0.9170 - lr: 5.0000e-04\n","Epoch 120/2000\n","781/781 [==============================] - 31s 39ms/step - loss: 0.2478 - accuracy: 0.9176 - val_loss: 0.2934 - val_accuracy: 0.9131 - lr: 5.0000e-04\n","Epoch 121/2000\n","781/781 [==============================] - 28s 36ms/step - loss: 0.2322 - accuracy: 0.9239 - val_loss: 0.2625 - val_accuracy: 0.9192 - lr: 2.5000e-04\n","Epoch 122/2000\n","781/781 [==============================] - 28s 36ms/step - loss: 0.2283 - accuracy: 0.9254 - val_loss: 0.2638 - val_accuracy: 0.9190 - lr: 2.5000e-04\n","Epoch 123/2000\n","781/781 [==============================] - 26s 33ms/step - loss: 0.2235 - accuracy: 0.9264 - val_loss: 0.2648 - val_accuracy: 0.9176 - lr: 2.5000e-04\n","Epoch 124/2000\n","781/781 [==============================] - 28s 36ms/step - loss: 0.2265 - accuracy: 0.9250 - val_loss: 0.2603 - val_accuracy: 0.9165 - lr: 2.5000e-04\n","Epoch 125/2000\n","781/781 [==============================] - 33s 43ms/step - loss: 0.2213 - accuracy: 0.9255 - val_loss: 0.2720 - val_accuracy: 0.9168 - lr: 2.5000e-04\n","Epoch 126/2000\n","781/781 [==============================] - 26s 34ms/step - loss: 0.2184 - accuracy: 0.9272 - val_loss: 0.2641 - val_accuracy: 0.9188 - lr: 2.5000e-04\n","Epoch 127/2000\n","781/781 [==============================] - 26s 34ms/step - loss: 0.2167 - accuracy: 0.9284 - val_loss: 0.2701 - val_accuracy: 0.9178 - lr: 2.5000e-04\n","Epoch 128/2000\n","781/781 [==============================] - 26s 34ms/step - loss: 0.2170 - accuracy: 0.9278 - val_loss: 0.2699 - val_accuracy: 0.9205 - lr: 2.5000e-04\n","Epoch 129/2000\n","781/781 [==============================] - 26s 34ms/step - loss: 0.2158 - accuracy: 0.9277 - val_loss: 0.2712 - val_accuracy: 0.9189 - lr: 2.5000e-04\n","Epoch 130/2000\n","781/781 [==============================] - 26s 33ms/step - loss: 0.2159 - accuracy: 0.9285 - val_loss: 0.2640 - val_accuracy: 0.9203 - lr: 2.5000e-04\n","Epoch 131/2000\n","781/781 [==============================] - 26s 34ms/step - loss: 0.2156 - accuracy: 0.9274 - val_loss: 0.2569 - val_accuracy: 0.9222 - lr: 2.5000e-04\n","Epoch 132/2000\n","781/781 [==============================] - 26s 33ms/step - loss: 0.2132 - accuracy: 0.9299 - val_loss: 0.2604 - val_accuracy: 0.9214 - lr: 2.5000e-04\n","Epoch 133/2000\n","341/781 [============>.................] - ETA: 13s - loss: 0.2172 - accuracy: 0.9265"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn [5], line 100\u001b[0m\n\u001b[0;32m     96\u001b[0m set_lr \u001b[39m=\u001b[39m RLROP(factor\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m, min_lr\u001b[39m=\u001b[39m\u001b[39m1e-8\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[0;32m     99\u001b[0m \u001b[39m## TRAINING with DA and LRA\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m history\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39;49mfit(datagen\u001b[39m.\u001b[39;49mflow(x_train, y_train,batch_size\u001b[39m=\u001b[39;49mbatch_size),\n\u001b[0;32m    101\u001b[0m                             steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(x_train) \u001b[39m/\u001b[39;49m batch_size, \n\u001b[0;32m    102\u001b[0m                             epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m    103\u001b[0m                             validation_data\u001b[39m=\u001b[39;49m(x_test, y_test),\n\u001b[0;32m    104\u001b[0m                             callbacks\u001b[39m=\u001b[39;49m[set_lr],\n\u001b[0;32m    105\u001b[0m                             verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m    108\u001b[0m \u001b[39m## TEST\u001b[39;00m\n\u001b[0;32m    109\u001b[0m scores \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(x_test, y_test, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n","File \u001b[1;32me:\\Anaconda\\envs\\vencevu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[1;32me:\\Anaconda\\envs\\vencevu\\lib\\site-packages\\keras\\engine\\training.py:1414\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1412\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs  \u001b[39m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[0;32m   1413\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[1;32m-> 1414\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[0;32m   1415\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[0;32m   1416\u001b[0m   \u001b[39mbreak\u001b[39;00m\n","File \u001b[1;32me:\\Anaconda\\envs\\vencevu\\lib\\site-packages\\keras\\callbacks.py:438\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \n\u001b[0;32m    433\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    436\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    437\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 438\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m'\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m'\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n","File \u001b[1;32me:\\Anaconda\\envs\\vencevu\\lib\\site-packages\\keras\\callbacks.py:297\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    295\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    296\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mend\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 297\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[0;32m    298\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    300\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. Expected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m)\n","File \u001b[1;32me:\\Anaconda\\envs\\vencevu\\lib\\site-packages\\keras\\callbacks.py:318\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m   batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[0;32m    316\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 318\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[0;32m    320\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    321\u001b[0m   end_hook_name \u001b[39m=\u001b[39m hook_name\n","File \u001b[1;32me:\\Anaconda\\envs\\vencevu\\lib\\site-packages\\keras\\callbacks.py:356\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[0;32m    355\u001b[0m   hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 356\u001b[0m   hook(batch, logs)\n\u001b[0;32m    358\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[0;32m    359\u001b[0m   \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n","File \u001b[1;32me:\\Anaconda\\envs\\vencevu\\lib\\site-packages\\keras\\callbacks.py:1034\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1033\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m-> 1034\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n","File \u001b[1;32me:\\Anaconda\\envs\\vencevu\\lib\\site-packages\\keras\\callbacks.py:1106\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1102\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m add_seen\n\u001b[0;32m   1104\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1105\u001b[0m   \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> 1106\u001b[0m   logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   1107\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen, \u001b[39mlist\u001b[39m(logs\u001b[39m.\u001b[39mitems()), finalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n","File \u001b[1;32me:\\Anaconda\\envs\\vencevu\\lib\\site-packages\\keras\\utils\\tf_utils.py:607\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    604\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n\u001b[0;32m    605\u001b[0m   \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(t) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m t\n\u001b[1;32m--> 607\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n","File \u001b[1;32me:\\Anaconda\\envs\\vencevu\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:916\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    912\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m    913\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    915\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 916\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    917\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n","File \u001b[1;32me:\\Anaconda\\envs\\vencevu\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:916\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    912\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m    913\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    915\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 916\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    917\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n","File \u001b[1;32me:\\Anaconda\\envs\\vencevu\\lib\\site-packages\\keras\\utils\\tf_utils.py:601\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    598\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    599\u001b[0m   \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m    600\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, tf\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m--> 601\u001b[0m     t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[0;32m    602\u001b[0m   \u001b[39m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[39;00m\n\u001b[0;32m    603\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(t, (np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mgeneric)):\n","File \u001b[1;32me:\\Anaconda\\envs\\vencevu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1159\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1136\u001b[0m \u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m \n\u001b[0;32m   1138\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1156\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1157\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1159\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1160\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n","File \u001b[1;32me:\\Anaconda\\envs\\vencevu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1125\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   1124\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1125\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[0;32m   1126\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["## DEF NN TOPOLOGY  \n","model = Sequential()\n","\n","model.add(Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(32,32,3)))\n","model.add(BN())\n","model.add(GN(0.3))\n","model.add(Conv2D(32, (3,3), padding='same', activation='relu'))\n","model.add(BN())\n","model.add(GN(0.3))\n","model.add(Conv2D(32, (3,3), padding='same', activation='relu'))\n","model.add(BN())\n","model.add(GN(0.3))\n","model.add(Conv2D(32, (3,3), padding='same', activation='relu'))\n","model.add(BN())\n","model.add(GN(0.3))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(DP(0.3))\n","\n","model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n","model.add(BN())\n","model.add(GN(0.3))\n","model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n","model.add(BN())\n","model.add(GN(0.3))\n","model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n","model.add(BN())\n","model.add(GN(0.3))\n","model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n","model.add(BN())\n","model.add(GN(0.3))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(DP(0.3))\n","\n","model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n","model.add(BN())\n","model.add(GN(0.3))\n","model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n","model.add(BN())\n","model.add(GN(0.3))\n","model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n","model.add(BN())\n","model.add(GN(0.3))\n","model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n","model.add(BN())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(DP(0.3))\n","\n","model.add(Conv2D(256, (3,3), padding='same', activation='relu'))\n","model.add(BN())\n","model.add(GN(0.3))\n","model.add(Conv2D(256, (3,3), padding='same', activation='relu'))\n","model.add(BN())\n","model.add(GN(0.3))\n","model.add(Conv2D(256, (3,3), padding='same', activation='relu'))\n","model.add(BN())\n","model.add(GN(0.3))\n","model.add(Conv2D(256, (3,3), padding='same', activation='relu'))\n","model.add(BN())\n","model.add(GN(0.3))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(DP(0.5))\n","\n","model.add(Conv2D(512, (3,3), padding='same', activation='relu'))\n","model.add(BN())\n","model.add(GN(0.3))\n","model.add(Conv2D(512, (3,3), padding='same', activation='relu'))\n","model.add(BN())\n","model.add(GN(0.3))\n","model.add(Conv2D(512, (3,3), padding='same', activation='relu'))\n","model.add(BN())\n","model.add(GN(0.3))\n","model.add(Conv2D(512, (3,3), padding='same', activation='relu'))\n","model.add(BN())\n","model.add(GN(0.3))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(DP(0.5))\n","\n","\n","model.add(Flatten())\n","model.add(Dense(256, activation='relu'))\n","model.add(BN())\n","model.add(DP(0.5))\n","model.add(Dense(num_classes, activation='softmax'))    # num_classes = 10\n","\n","model.summary()\n","\n","\n","## OPTIM AND COMPILE\n","opt = Adam(learning_rate=0.001)\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=opt,\n","              metrics=['accuracy'])\n","\n","# DEFINE A LEARNING RATE SCHEDULER\n","set_lr = RLROP(factor=0.5, min_lr=1e-8, patience=10)\n","\n","\n","## TRAINING with DA and LRA\n","history=model.fit(datagen.flow(x_train, y_train,batch_size=batch_size),\n","                            steps_per_epoch=len(x_train) / batch_size, \n","                            epochs=epochs,\n","                            validation_data=(x_test, y_test),\n","                            callbacks=[set_lr],\n","                            verbose=1)\n","\n","\n","## TEST\n","scores = model.evaluate(x_test, y_test, verbose=1)\n","print('Test loss:', scores[0])\n","print('Test accuracy:', scores[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"aborted","timestamp":1673515868445,"user":{"displayName":"Vencevú '_'","userId":"04987947938800528309"},"user_tz":-60},"id":"PWQxFKX339DJ"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPOEGOdqa/ZgxGO37QwygPa","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"vencevu","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"vscode":{"interpreter":{"hash":"88a2c52dd2244db0db2d2f6b636ef43ce35273efa1a6ae2eb619080e9fb1309e"}}},"nbformat":4,"nbformat_minor":0}
